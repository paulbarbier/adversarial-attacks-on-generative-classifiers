{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\orbax\\checkpoint\\type_handlers.py:1346: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "import os\n",
    "from ml_collections import ConfigDict\n",
    "from pathlib import Path\n",
    "from utils import prepare_test_dataset\n",
    "from dataset_utils import get_dataset\n",
    "from jax import random\n",
    "from models.utils import sample_gaussian\n",
    "\n",
    "import models.ClassifierGFZ as ClassifierGFZ\n",
    "import models.ClassifierDFZ as ClassifierDFZ\n",
    "\n",
    "checkpoint_path = \"dfz-2-epochs-first-try-1\"\n",
    "path = os.path.join(Path.cwd(), Path(f\"checkpoints\"), Path(checkpoint_path))\n",
    "checkpoint = ocp.PyTreeCheckpointer().restore(path, item=None)\n",
    "\n",
    "config = ConfigDict(checkpoint[\"config\"])\n",
    "dataset_config = ConfigDict(checkpoint[\"dataset_config\"])\n",
    "\n",
    "if config.model_name == \"GFZ\":\n",
    "    classifier = ClassifierGFZ\n",
    "elif config.model_name == \"DFZ\":\n",
    "    classifier = ClassifierDFZ\n",
    "else:\n",
    "    raise NotImplementedError(config.model_name)\n",
    "\n",
    "_, test_ds = get_dataset(config.dataset)\n",
    "test_images, test_labels = prepare_test_dataset(\n",
    "    test_ds, dataset_config\n",
    "    )\n",
    "\n",
    "trained_params = checkpoint[\"params\"]\n",
    "\n",
    "log_likelyhood_fn = classifier.log_likelyhood_A\n",
    "\n",
    "test_key = random.PRNGKey(config.seed)\n",
    "\n",
    "test_key, model, _ = classifier.create_and_init(\n",
    "    test_key, config, dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import jacrev\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def init_data(test_key, n_samples=10):\n",
    "    idx = np.random.choice(range(len(test_images)), n_samples, replace=False)\n",
    "\n",
    "    all_xs = test_images[idx]\n",
    "    true_ys = test_labels[idx]\n",
    "    true_labels = np.argmax(true_ys, axis=1)\n",
    "\n",
    "    K = model.K\n",
    "    batch_size = n_samples\n",
    "    test_key, epsilons = sample_gaussian(test_key, (batch_size, model.n_classes * K, model.d_latent))\n",
    "    epsilons = epsilons[:n_samples*model.n_classes]\n",
    "    all_ys = nn.one_hot(jnp.repeat(jnp.arange(model.n_classes), K), model.n_classes, dtype=jnp.float32)\n",
    "    \n",
    "    return all_xs, true_labels, epsilons, all_ys, K, test_key\n",
    "\n",
    "def get_model_output(x, epsilon, y, K):\n",
    "    z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz = jax.vmap(\n",
    "            partial(model.apply, {'params': trained_params}, train=False),\n",
    "            in_axes=(None, 0, 0)\n",
    "        )(x, y, epsilon)\n",
    "\n",
    "    ll = log_likelyhood_fn(\n",
    "            z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz\n",
    "        ).reshape(model.n_classes, K)\n",
    "    ll = logsumexp(ll, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def get_model_jacobian(x, epsilon, y, K):\n",
    "    return jacrev(get_model_output, argnums=0)(x, epsilon, y, K)\n",
    "\n",
    "def map_label_to_name(y):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constrained_BFGS_B():\n",
    "    def __init__(self, f, grad, x0, bounds, maxiter=1000, eps=1e-8):\n",
    "        self.f = f\n",
    "        self.grad = grad\n",
    "        self.x0 = x0\n",
    "        self.bounds = bounds\n",
    "        self.maxiter = maxiter\n",
    "        self.eps = eps\n",
    "\n",
    "    def line_search(self, x, direction, alpha = 0.4, beta=0.8, max_iter=1000):\n",
    "        step_size = 1\n",
    "        i = 0\n",
    "        while i < max_iter:\n",
    "            if self.f(x + step_size  * direction) <= self.f(x) + step_size * alpha * direction.dot(self.grad(x)):\n",
    "                break\n",
    "            step_size  *= beta\n",
    "            i += 1\n",
    "            \n",
    "        return step_size\n",
    "    \n",
    "    def determine_active_set(self, x, bounds):\n",
    "        active_set = np.ones_like(x, dtype=bool)\n",
    "\n",
    "        for i, (lower_bound, upper_bound) in enumerate(bounds):\n",
    "            if lower_bound is not None and x[i] <= lower_bound:\n",
    "                active_set[i] = False  # Variable is at the lower bound\n",
    "            elif upper_bound is not None and x[i] >= upper_bound:\n",
    "                active_set[i] = False  # Variable is at the upper bound\n",
    "\n",
    "        return active_set\n",
    "    \n",
    "    def update_inverse_hessian_bfgs_b(self, Bk, sk, yk, active_set):\n",
    "        sk_active = sk[active_set]\n",
    "        yk_active = yk[active_set]\n",
    "\n",
    "        if not any(active_set):\n",
    "            return Bk\n",
    "\n",
    "        rho = 1 / np.dot(yk_active, sk_active)\n",
    "        term1 = np.eye(len(sk_active)) - np.outer(sk_active, yk_active) * rho\n",
    "        term2 = np.eye(len(sk_active)) - np.outer(yk_active, sk_active) * rho\n",
    "        Bk1_active = np.dot(term1, np.dot(Bk, term2)) + np.outer(rho * sk_active, sk_active)\n",
    "        Bk1 = Bk.copy()\n",
    "        Bk1[np.ix_(active_set, active_set)] = Bk1_active\n",
    "\n",
    "        return Bk1\n",
    "\n",
    "    def optimize(self):\n",
    "        x = self.x0\n",
    "        B = np.eye(len(x))\n",
    "        for i in range(self.maxiter):\n",
    "            g = self.grad(x)\n",
    "            if np.linalg.norm(g) < self.eps:\n",
    "                break\n",
    "            direction = -B.dot(g)\n",
    "            step_size = self.line_search(x, direction)\n",
    "            x_new = x + step_size * direction\n",
    "            s = x_new - x\n",
    "            y = self.grad(x_new) - g\n",
    "            active_set = self.determine_active_set(x_new, self.bounds)\n",
    "            B = self.update_inverse_hessian_bfgs_b(B, s, y, active_set)\n",
    "            x = x_new\n",
    "            print(self.f(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from jaxopt import ScipyBoundedMinimize\n",
    "\n",
    "class L_BGFS_Attack():\n",
    "    def __init__(self, model, max_iter=100, learning_rate=1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J.flatten()\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K, c = 1):\n",
    "        corrupted_x = x.copy()\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        self.c = c\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = x\n",
    "\n",
    "        # Line search for c\n",
    "        for label in range(self.n_classes):\n",
    "            if label != true_label:\n",
    "                def get_problem(r):\n",
    "                    corrupted_x = x + r\n",
    "                    val = self.get_likelihoods(corrupted_x)\n",
    "                    return jnp.sum(self.qnorm(r) + self.loss(val, label))\n",
    "\n",
    "                r_init = jnp.zeros_like(x)\n",
    "                lbfgsb = ScipyBoundedMinimize(fun=get_problem, method=\"l-bfgs-b\")\n",
    "                lower_bounds = jnp.zeros_like(r_init)\n",
    "                upper_bounds = jnp.ones_like(r_init)\n",
    "                bounds = (lower_bounds, upper_bounds)\n",
    "                r = lbfgsb.run(r_init, bounds=bounds).params\n",
    "                corrupted_x = x + r\n",
    "\n",
    "                # i = 0\n",
    "                # optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "                # state = optimizer.init(jax.device_put(r.flatten()))\n",
    "                # while i < self.max_iter:\n",
    "                    # grad = jax.grad(get_problem)(jax.device_put(r.flatten()))\n",
    "                    # updates, state = optimizer.update(grad, state)\n",
    "                    # r = optax.apply_updates(jax.device_put(r.flatten()), updates).reshape(corrupted_x.shape)\n",
    "                    # corrupted_x = self.project_to_bounds(corrupted_x + r, bounds)\n",
    "\n",
    "\n",
    "                    # if self.get_label(corrupted_x) == label:\n",
    "                    #     break\n",
    "                    # else:\n",
    "                    #     i += 1\n",
    "\n",
    "                # check if the attack was successful\n",
    "                new_label = self.get_label(corrupted_x)\n",
    "                if new_label != label:\n",
    "                    print(\"Warning: did not find a perturbation\")\n",
    "                    perturbation_norm = -1\n",
    "                else:\n",
    "                    perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "                    print(perturbation_norm)\n",
    "                # Choose minimal perturbation\n",
    "                if max_perturbation_norm == -1 and perturbation_norm != -1:\n",
    "                    max_perturbation_norm = perturbation_norm\n",
    "                    best_label = new_label\n",
    "                    best_corrupted_x = corrupted_x\n",
    "                else : \n",
    "                    if perturbation_norm != -1 and perturbation_norm < max_perturbation_norm:\n",
    "                        max_perturbation_norm = perturbation_norm\n",
    "                        best_label = new_label\n",
    "                        best_corrupted_x = corrupted_x\n",
    "\n",
    "        return best_corrupted_x, best_label, max_perturbation_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_performance(corruption_model, all_xs, epsilons, all_ys, K):\n",
    "    perturbation_norms = []\n",
    "    n_samples = len(all_xs)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        x = all_xs[i]\n",
    "        epsilon = epsilons[i]\n",
    "        _, _, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "        perturbation_norms.append(perturbation_norm)\n",
    "    return np.array(perturbation_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0.000576]\n",
      "[3.31776e-07]\n",
      "[1.17549435e-38]\n",
      "[1.17549435e-38]\n"
     ]
    }
   ],
   "source": [
    "#Testing optimization algorithm\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def grad(x):\n",
    "    return 2*x\n",
    "f = f\n",
    "g = grad\n",
    "bounds = [(0, 1)] * 1\n",
    "i = 0\n",
    "corrupted_x = np.array([1])\n",
    "print(f(corrupted_x))\n",
    "BFGS = Constrained_BFGS_B(f, g, corrupted_x, bounds)\n",
    "r = BFGS.optimize()\n",
    "print(f(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = L_BGFS_Attack(model)\n",
    "\n",
    "perturbation_norms_BFGS = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_BFGS = perturbation_norms_BFGS[perturbation_norms_BFGS != -1]\n",
    "n_successful_BFGS = len(perturbation_norms_successful_BFGS)\n",
    "n_successful_BFGS\n",
    "print(f'Average perturbation norm of L_BGFS Attack model (on {n_successful_BFGS} successful samples): {np.mean(perturbation_norms_successful_BFGS):>.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagner and carlini attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class WG_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c = 1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(1/2 * jnp.tanh(w) + 1/2 - x)\n",
    "        penalty = self.c * self.f(1/2 * jnp.tanh(w) + 1/2, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x, target_label):\n",
    "        corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "        norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != target_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = max_logit - val[target_label]\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[max_label] - grad_model[target_label]\n",
    "        \n",
    "        return jnp.sum(norm_grad + self.c * penalty_grad)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        x =jax.device_put(x)\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = x\n",
    "        for label in range(self.n_classes): # to do : optimize this loop\n",
    "            if label != true_label:\n",
    "                # use adam optimizer to find minimum of the problem\n",
    "                w = jnp.zeros_like(x)\n",
    "                optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "                state = optimizer.init(jax.device_put(w))\n",
    "                for i in range(self.max_iter):\n",
    "                    corrupted_x = x.copy()                   \n",
    "\n",
    "                    grad = self.get_obj_grad(w, x, label)\n",
    "                    # grad = jax.grad(self.get_objective)(w, x, label)\n",
    "                    # print(\"grad norm : \", np.linalg.norm(grad))\n",
    "\n",
    "                    updates, state = optimizer.update(grad, state)\n",
    "                    w = optax.apply_updates(jax.device_put(w), updates)\n",
    "                    # w = w - self.learning_rate * grad\n",
    "                    corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "                    print(corrupted_x)\n",
    "                    plt.imshow(corrupted_x.reshape(28, 28), cmap=\"gray\")\n",
    "                    if self.get_label(corrupted_x) == label:\n",
    "                        break\n",
    "                    \n",
    "                # check if the attack was successful\n",
    "                new_label = self.get_label(corrupted_x)\n",
    "                if new_label != label:\n",
    "                    print(\"Warning: did not find a perturbation\")\n",
    "                    perturbation_norm = -1\n",
    "                else:\n",
    "                    perturbation_norm = jnp.linalg.norm(corrupted_x - x)/jnp.linalg.norm(x)\n",
    "                # Choose minimal perturbation\n",
    "                if max_perturbation_norm == -1 and perturbation_norm != -1:\n",
    "                    max_perturbation_norm = perturbation_norm\n",
    "                    best_label = new_label\n",
    "                    best_corrupted_x = corrupted_x\n",
    "                else : \n",
    "                    if perturbation_norm != -1 and perturbation_norm < max_perturbation_norm:\n",
    "                        max_perturbation_norm = perturbation_norm\n",
    "                        best_label = new_label\n",
    "                        best_corrupted_x = corrupted_x\n",
    "\n",
    "        return best_corrupted_x, best_label, max_perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagner and carlini attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class untargeted_WG_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c = 1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(1/2 * jnp.tanh(w) + 1/2 - x)\n",
    "        penalty = self.c * self.f(1/2 * jnp.tanh(w) + 1/2, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x):\n",
    "        corrupted_x = x + w\n",
    "        # corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "        norm_grad = 2 * (corrupted_x - x)\n",
    "        # norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != self.true_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = val[self.true_label] - max_logit\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[self.true_label] - grad_model[max_label]\n",
    "        \n",
    "        return jnp.sum(norm_grad + self.c * penalty_grad)\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        x = jax.device_put(x)\n",
    "        self.true_label = self.get_label(x)\n",
    "        # use adam optimizer to find minimum of the problem\n",
    "        w = jnp.zeros_like(x)\n",
    "        optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "        state = optimizer.init(jax.device_put(w))\n",
    "        for i in range(self.max_iter):\n",
    "            corrupted_x = x.copy()\n",
    "            grad = self.get_obj_grad(w, x)\n",
    "            # grad = jax.grad(self.get_objective)(w, x, label)\n",
    "            # print(\"grad norm : \", np.linalg.norm(grad))\n",
    "\n",
    "            updates, state = optimizer.update(grad, state)\n",
    "            w = optax.apply_updates(jax.device_put(w), updates)\n",
    "            # w = w - self.learning_rate * grad\n",
    "            # corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "            corrupted_x = x + w\n",
    "            corrupted_x = self.project_to_bounds(corrupted_x)\n",
    "            if self.get_label(corrupted_x) != self.true_label:\n",
    "                break\n",
    "            \n",
    "        # check if the attack was successful\n",
    "        new_label = self.get_label(corrupted_x)\n",
    "        if new_label == self.true_label:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "        else:\n",
    "            perturbation_norm = jnp.linalg.norm(corrupted_x - x)/jnp.linalg.norm(x)\n",
    "\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m all_xs, true_labels, epsilons, all_ys, K, test_key \u001b[38;5;241m=\u001b[39m init_data(test_key, n_samples\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[0;32m      4\u001b[0m corruption_model \u001b[38;5;241m=\u001b[39m untargeted_WG_Attack(model, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.10\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m perturbation_norms_WG \u001b[38;5;241m=\u001b[39m \u001b[43mget_average_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorruption_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m perturbation_norms_successful_WG \u001b[38;5;241m=\u001b[39m perturbation_norms_WG[perturbation_norms_WG \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m n_successful_WG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(perturbation_norms_successful_WG)\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mget_average_performance\u001b[1;34m(corruption_model, all_xs, epsilons, all_ys, K)\u001b[0m\n\u001b[0;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m all_xs[i]\n\u001b[0;32m      6\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m epsilons[i]\n\u001b[1;32m----> 7\u001b[0m     _, _, perturbation_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcorruption_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     perturbation_norms\u001b[38;5;241m.\u001b[39mappend(perturbation_norm)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(perturbation_norms)\n",
      "Cell \u001b[1;32mIn[18], line 86\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_perturbation\u001b[1;34m(self, x, epsilon, all_ys, K)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m     85\u001b[0m     corrupted_x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 86\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_obj_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# grad = jax.grad(self.get_objective)(w, x, label)\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# print(\"grad norm : \", np.linalg.norm(grad))\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     updates, state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grad, state)\n",
      "Cell \u001b[1;32mIn[18], line 58\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_obj_grad\u001b[1;34m(self, w, x)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_likelihoods(corrupted_x)\n\u001b[1;32m---> 58\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m max_label \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39margmax(val[jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_label])\n\u001b[0;32m     60\u001b[0m max_logit \u001b[38;5;241m=\u001b[39m val[max_label]\n",
      "Cell \u001b[1;32mIn[18], line 33\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_gradients\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 33\u001b[0m     J \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m J\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mget_model_jacobian\u001b[1;34m(x, epsilon, y, K)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_jacobian\u001b[39m(x, epsilon, y, K):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_model_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:945\u001b[0m, in \u001b[0;36mjacrev.<locals>.jacfun\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m   y, pullback, aux \u001b[38;5;241m=\u001b[39m _vjp(f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    944\u001b[0m tree_map(partial(_check_output_dtype_jacrev, holomorphic), y)\n\u001b[1;32m--> 945\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpullback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_std_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    946\u001b[0m jac \u001b[38;5;241m=\u001b[39m jac[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m jac\n\u001b[0;32m    947\u001b[0m example_args \u001b[38;5;241m=\u001b[39m dyn_args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m dyn_args\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:1258\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1255\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1256\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 1258\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\tree_util.py:357\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m--> 357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:2148\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[1;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[0;32m   2143\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[0;32m   2144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2148\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\tree_util.py:357\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m--> 357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:149\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[1;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[0;32m    147\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[0;32m    148\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[1;32m--> 149\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:253\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[0;32m    250\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[0;32m    251\u001b[0m       params, call_jaxpr, invals, cts_in, cts_in_avals, reduce_axes)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mprimitive \u001b[38;5;129;01min\u001b[39;00m reducing_transposes:\n\u001b[1;32m--> 253\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m reducing_transposes[eqn\u001b[38;5;241m.\u001b[39mprimitive](\n\u001b[0;32m    254\u001b[0m       reduce_axes, cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[0;32m    257\u001b[0m       cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1748\u001b[0m, in \u001b[0;36m_pjit_transpose\u001b[1;34m(reduce_axes, cts_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *primals_in)\u001b[0m\n\u001b[0;32m   1742\u001b[0m cts_out_treedef \u001b[38;5;241m=\u001b[39m cts_out_treedef_thunk()\n\u001b[0;32m   1743\u001b[0m transpose_out_shardings \u001b[38;5;241m=\u001b[39m prune_type(\n\u001b[0;32m   1744\u001b[0m     ad\u001b[38;5;241m.\u001b[39mZero,\n\u001b[0;32m   1745\u001b[0m     in_shardings,\n\u001b[0;32m   1746\u001b[0m     tree_unflatten(cts_out_treedef, [\u001b[38;5;28mobject\u001b[39m()] \u001b[38;5;241m*\u001b[39m cts_out_treedef\u001b[38;5;241m.\u001b[39mnum_leaves))\n\u001b[1;32m-> 1748\u001b[0m nz_cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_in_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_out_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(cts_out_treedef, nz_cts_out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\batching.py:433\u001b[0m, in \u001b[0;36mBatchTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    431\u001b[0m   frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_frame(vals_in, dims_in)\n\u001b[0;32m    432\u001b[0m   batched_primitive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_primitive_batcher(primitive, frame)\n\u001b[1;32m--> 433\u001b[0m   val_out, dim_out \u001b[38;5;241m=\u001b[39m batched_primitive(vals_in, dims_in, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    434\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1490\u001b[0m, in \u001b[0;36m_pjit_batcher\u001b[1;34m(insert_axis, spmd_axis_name, axis_size, axis_name, main_type, vals_in, dims_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline)\u001b[0m\n\u001b[0;32m   1482\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m   1483\u001b[0m     _pjit_batcher_for_sharding(i, axis_in, new_parts, mesh, aval\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m i\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis_in, i, aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dims_in, in_shardings, new_jaxpr\u001b[38;5;241m.\u001b[39min_avals))\n\u001b[0;32m   1486\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m   1487\u001b[0m     _pjit_batcher_for_sharding(o, axis_out, new_parts, mesh, aval\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m o\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis_out, o, aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes_out, out_shardings, new_jaxpr\u001b[38;5;241m.\u001b[39mout_avals))\n\u001b[1;32m-> 1490\u001b[0m vals_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m  \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m  \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1500\u001b[0m resolved_axes_out \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mresolve_ragged_axes_against_inputs_outputs(\n\u001b[0;32m   1501\u001b[0m     vals_in, vals_out, axes_out)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals_out, resolved_axes_out\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1245\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[1;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[0;32m   1242\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d]\n\u001b[0;32m   1243\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[0;32m   1244\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = untargeted_WG_Attack(model, max_iter=100, learning_rate=0.1, c = 0.10, p=2)\n",
    "\n",
    "perturbation_norms_WG = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_WG = perturbation_norms_WG[perturbation_norms_WG != -1]\n",
    "n_successful_WG = len(perturbation_norms_successful_WG)\n",
    "n_successful_WG\n",
    "print(f'Average perturbation norm of Wagner & Carlini Attack model (on {n_successful_WG} successful samples): {np.mean(perturbation_norms_successful_WG):>.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(range(n_samples))\n",
    "x = all_xs[i]\n",
    "true_label = true_labels[i]\n",
    "test_key, epsilons = sample_gaussian(test_key, (1, model.n_classes * K, model.d_latent))\n",
    "epsilon = epsilons[0]\n",
    "\n",
    "corruption_model = untargeted_WG_Attack(model, max_iter=100, learning_rate=0.0001, c = 0.1, p=2)\n",
    "corrupted_x, new_label, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[0].set_title(f\"Original image (label = '{map_label_to_name(true_label)}')\")\n",
    "\n",
    "axs[1].imshow(corrupted_x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[1].set_title(f\"Carlini and Wagner perturbated image (label = '{map_label_to_name(new_label)}')\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
