{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\orbax\\checkpoint\\type_handlers.py:1346: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "import os\n",
    "from ml_collections import ConfigDict\n",
    "from pathlib import Path\n",
    "from utils import prepare_test_dataset\n",
    "from dataset_utils import get_dataset\n",
    "from jax import random\n",
    "from models.utils import sample_gaussian\n",
    "\n",
    "import models.ClassifierGFZ as ClassifierGFZ\n",
    "import models.ClassifierDFZ as ClassifierDFZ\n",
    "\n",
    "checkpoint_path = \"dfz-2-epochs-first-try-1\"\n",
    "path = os.path.join(Path.cwd(), Path(f\"checkpoints\"), Path(checkpoint_path))\n",
    "checkpoint = ocp.PyTreeCheckpointer().restore(path, item=None)\n",
    "\n",
    "config = ConfigDict(checkpoint[\"config\"])\n",
    "dataset_config = ConfigDict(checkpoint[\"dataset_config\"])\n",
    "\n",
    "if config.model_name == \"GFZ\":\n",
    "    classifier = ClassifierGFZ\n",
    "elif config.model_name == \"DFZ\":\n",
    "    classifier = ClassifierDFZ\n",
    "else:\n",
    "    raise NotImplementedError(config.model_name)\n",
    "\n",
    "_, test_ds = get_dataset(config.dataset)\n",
    "test_images, test_labels = prepare_test_dataset(\n",
    "    test_ds, dataset_config\n",
    "    )\n",
    "\n",
    "trained_params = checkpoint[\"params\"]\n",
    "\n",
    "log_likelyhood_fn = classifier.log_likelyhood_A\n",
    "\n",
    "test_key = random.PRNGKey(config.seed)\n",
    "\n",
    "test_key, model, _ = classifier.create_and_init(\n",
    "    test_key, config, dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import jacrev\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def init_data(test_key, n_samples=10):\n",
    "    idx = np.random.choice(range(len(test_images)), n_samples, replace=False)\n",
    "\n",
    "    all_xs = test_images[idx]\n",
    "    true_ys = test_labels[idx]\n",
    "    true_labels = np.argmax(true_ys, axis=1)\n",
    "\n",
    "    K = model.K\n",
    "    batch_size = n_samples\n",
    "    test_key, epsilons = sample_gaussian(test_key, (batch_size, model.n_classes * K, model.d_latent))\n",
    "    epsilons = epsilons[:n_samples*model.n_classes]\n",
    "    all_ys = nn.one_hot(jnp.repeat(jnp.arange(model.n_classes), K), model.n_classes, dtype=jnp.float32)\n",
    "    \n",
    "    return all_xs, true_labels, epsilons, all_ys, K, test_key\n",
    "\n",
    "def get_model_output(x, epsilon, y, K):\n",
    "    z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz = jax.vmap(\n",
    "            partial(model.apply, {'params': trained_params}, train=False),\n",
    "            in_axes=(None, 0, 0)\n",
    "        )(x, y, epsilon)\n",
    "\n",
    "    ll = log_likelyhood_fn(\n",
    "            z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz\n",
    "        ).reshape(model.n_classes, K)\n",
    "    ll = logsumexp(ll, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def get_model_jacobian(x, epsilon, y, K):\n",
    "    return jacrev(get_model_output, argnums=0)(x, epsilon, y, K)\n",
    "\n",
    "def map_label_to_name(y):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constrained_BFGS_B():\n",
    "    def __init__(self, f, grad, x0, bounds, maxiter=1000, eps=1e-8):\n",
    "        self.f = f\n",
    "        self.grad = grad\n",
    "        self.x0 = x0\n",
    "        self.bounds = bounds\n",
    "        self.maxiter = maxiter\n",
    "        self.eps = eps\n",
    "\n",
    "    def line_search(self, x, direction, alpha = 0.4, beta=0.8, max_iter=1000):\n",
    "        step_size = 1\n",
    "        i = 0\n",
    "        while i < max_iter:\n",
    "            if self.f(x + step_size  * direction) <= self.f(x) + step_size * alpha * direction.dot(self.grad(x)):\n",
    "                break\n",
    "            step_size  *= beta\n",
    "            i += 1\n",
    "            \n",
    "        return step_size\n",
    "    \n",
    "    def determine_active_set(self, x, bounds):\n",
    "        active_set = np.ones_like(x, dtype=bool)\n",
    "\n",
    "        for i, (lower_bound, upper_bound) in enumerate(bounds):\n",
    "            if lower_bound is not None and x[i] <= lower_bound:\n",
    "                active_set[i] = False  # Variable is at the lower bound\n",
    "            elif upper_bound is not None and x[i] >= upper_bound:\n",
    "                active_set[i] = False  # Variable is at the upper bound\n",
    "\n",
    "        return active_set\n",
    "    \n",
    "    def update_inverse_hessian_bfgs_b(self, Bk, sk, yk, active_set):\n",
    "        sk_active = sk[active_set]\n",
    "        yk_active = yk[active_set]\n",
    "\n",
    "        if not any(active_set):\n",
    "            return Bk\n",
    "\n",
    "        rho = 1 / np.dot(yk_active, sk_active)\n",
    "        term1 = np.eye(len(sk_active)) - np.outer(sk_active, yk_active) * rho\n",
    "        term2 = np.eye(len(sk_active)) - np.outer(yk_active, sk_active) * rho\n",
    "        Bk1_active = np.dot(term1, np.dot(Bk, term2)) + np.outer(rho * sk_active, sk_active)\n",
    "        Bk1 = Bk.copy()\n",
    "        Bk1[np.ix_(active_set, active_set)] = Bk1_active\n",
    "\n",
    "        return Bk1\n",
    "\n",
    "    def optimize(self):\n",
    "        x = self.x0\n",
    "        B = np.eye(len(x))\n",
    "        for i in range(self.maxiter):\n",
    "            g = self.grad(x)\n",
    "            if np.linalg.norm(g) < self.eps:\n",
    "                break\n",
    "            direction = -B.dot(g)\n",
    "            step_size = self.line_search(x, direction)\n",
    "            x_new = x + step_size * direction\n",
    "            s = x_new - x\n",
    "            y = self.grad(x_new) - g\n",
    "            active_set = self.determine_active_set(x_new, self.bounds)\n",
    "            B = self.update_inverse_hessian_bfgs_b(B, s, y, active_set)\n",
    "            x = x_new\n",
    "            print(self.f(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from jaxopt import ScipyBoundedMinimize\n",
    "\n",
    "class L_BGFS_Attack():\n",
    "    def __init__(self, model, max_iter=100, learning_rate=1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J.flatten()\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K, c = 1):\n",
    "        corrupted_x = x.copy()\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        self.c = c\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = x\n",
    "\n",
    "        # Line search for c\n",
    "        for label in range(self.n_classes):\n",
    "            if label != true_label:\n",
    "                def get_problem(r):\n",
    "                    corrupted_x = x + r\n",
    "                    val = self.get_likelihoods(corrupted_x)\n",
    "                    return jnp.sum(self.qnorm(r) + self.loss(val, label))\n",
    "\n",
    "                r_init = jnp.zeros_like(x)\n",
    "                lbfgsb = ScipyBoundedMinimize(fun=get_problem, method=\"l-bfgs-b\")\n",
    "                lower_bounds = jnp.zeros_like(r_init)\n",
    "                upper_bounds = jnp.ones_like(r_init)\n",
    "                bounds = (lower_bounds, upper_bounds)\n",
    "                r = lbfgsb.run(r_init, bounds=bounds).params\n",
    "                corrupted_x = x + r\n",
    "\n",
    "                # i = 0\n",
    "                # optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "                # state = optimizer.init(jax.device_put(r.flatten()))\n",
    "                # while i < self.max_iter:\n",
    "                    # grad = jax.grad(get_problem)(jax.device_put(r.flatten()))\n",
    "                    # updates, state = optimizer.update(grad, state)\n",
    "                    # r = optax.apply_updates(jax.device_put(r.flatten()), updates).reshape(corrupted_x.shape)\n",
    "                    # corrupted_x = self.project_to_bounds(corrupted_x + r, bounds)\n",
    "\n",
    "\n",
    "                    # if self.get_label(corrupted_x) == label:\n",
    "                    #     break\n",
    "                    # else:\n",
    "                    #     i += 1\n",
    "\n",
    "                # check if the attack was successful\n",
    "                new_label = self.get_label(corrupted_x)\n",
    "                if new_label != label:\n",
    "                    print(\"Warning: did not find a perturbation\")\n",
    "                    perturbation_norm = -1\n",
    "                else:\n",
    "                    perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "                    print(perturbation_norm)\n",
    "                # Choose minimal perturbation\n",
    "                if max_perturbation_norm == -1 and perturbation_norm != -1:\n",
    "                    max_perturbation_norm = perturbation_norm\n",
    "                    best_label = new_label\n",
    "                    best_corrupted_x = corrupted_x\n",
    "                else : \n",
    "                    if perturbation_norm != -1 and perturbation_norm < max_perturbation_norm:\n",
    "                        max_perturbation_norm = perturbation_norm\n",
    "                        best_label = new_label\n",
    "                        best_corrupted_x = corrupted_x\n",
    "\n",
    "        return best_corrupted_x, best_label, max_perturbation_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_performance(corruption_model, all_xs, epsilons, all_ys, K):\n",
    "    perturbation_norms = []\n",
    "    n_samples = len(all_xs)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        x = all_xs[i]\n",
    "        epsilon = epsilons[i]\n",
    "        _, _, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "        perturbation_norms.append(perturbation_norm)\n",
    "    return np.array(perturbation_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0.000576]\n",
      "[3.31776e-07]\n",
      "[1.17549435e-38]\n",
      "[1.17549435e-38]\n"
     ]
    }
   ],
   "source": [
    "#Testing optimization algorithm\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def grad(x):\n",
    "    return 2*x\n",
    "f = f\n",
    "g = grad\n",
    "bounds = [(0, 1)] * 1\n",
    "i = 0\n",
    "corrupted_x = np.array([1])\n",
    "print(f(corrupted_x))\n",
    "BFGS = Constrained_BFGS_B(f, g, corrupted_x, bounds)\n",
    "r = BFGS.optimize()\n",
    "print(f(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:54<08:06, 54.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:52<07:33, 56.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:43<06:19, 54.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:34<05:18, 53.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [04:25<04:19, 51.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [05:15<03:25, 51.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [06:05<02:32, 50.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [06:56<01:41, 50.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:46<00:50, 50.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n",
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:39<00:00, 51.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n",
      "Average perturbation norm of L_BGFS Attack model (on 0 successful samples): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = L_BGFS_Attack(model)\n",
    "\n",
    "perturbation_norms_BFGS = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_BFGS = perturbation_norms_BFGS[perturbation_norms_BFGS != -1]\n",
    "n_successful_BFGS = len(perturbation_norms_successful_BFGS)\n",
    "n_successful_BFGS\n",
    "print(f'Average perturbation norm of L_BGFS Attack model (on {n_successful_BFGS} successful samples): {np.mean(perturbation_norms_successful_BFGS):>.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagner and carlini attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class WG_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c = 1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(1/2 * jnp.tanh(w) + 1/2 - x)\n",
    "        penalty = self.c * self.f(1/2 * jnp.tanh(w) + 1/2, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x, target_label):\n",
    "        corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "        norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != target_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = max_logit - val[target_label]\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[max_label] - grad_model[target_label]\n",
    "        \n",
    "        return jnp.sum(norm_grad + self.c * penalty_grad)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        x =jax.device_put(x)\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = x\n",
    "        for label in range(self.n_classes): # to do : optimize this loop\n",
    "            if label != true_label:\n",
    "                # use adam optimizer to find minimum of the problem\n",
    "                w = jnp.zeros_like(x)\n",
    "                optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "                state = optimizer.init(jax.device_put(w))\n",
    "                for i in range(self.max_iter):\n",
    "                    corrupted_x = x.copy()                   \n",
    "\n",
    "                    grad = self.get_obj_grad(w, x, label)\n",
    "                    # grad = jax.grad(self.get_objective)(w, x, label)\n",
    "                    # print(\"grad norm : \", np.linalg.norm(grad))\n",
    "\n",
    "                    updates, state = optimizer.update(grad, state)\n",
    "                    w = optax.apply_updates(jax.device_put(w), updates)\n",
    "                    # w = w - self.learning_rate * grad\n",
    "                    corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "                    print(corrupted_x)\n",
    "                    plt.imshow(corrupted_x.reshape(28, 28), cmap=\"gray\")\n",
    "                    if self.get_label(corrupted_x) == label:\n",
    "                        break\n",
    "                    \n",
    "                # check if the attack was successful\n",
    "                new_label = self.get_label(corrupted_x)\n",
    "                if new_label != label:\n",
    "                    print(\"Warning: did not find a perturbation\")\n",
    "                    perturbation_norm = -1\n",
    "                else:\n",
    "                    perturbation_norm = jnp.linalg.norm(corrupted_x - x)/jnp.linalg.norm(x)\n",
    "                # Choose minimal perturbation\n",
    "                if max_perturbation_norm == -1 and perturbation_norm != -1:\n",
    "                    max_perturbation_norm = perturbation_norm\n",
    "                    best_label = new_label\n",
    "                    best_corrupted_x = corrupted_x\n",
    "                else : \n",
    "                    if perturbation_norm != -1 and perturbation_norm < max_perturbation_norm:\n",
    "                        max_perturbation_norm = perturbation_norm\n",
    "                        best_label = new_label\n",
    "                        best_corrupted_x = corrupted_x\n",
    "\n",
    "        return best_corrupted_x, best_label, max_perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagner and carlini attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class untargeted_WG_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c = 1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x):\n",
    "        J = get_model_jacobian(x, self.epsilon, self.y, self.K)\n",
    "        return J\n",
    "\n",
    "    def loss(self, val, label):\n",
    "        label_one_hot_encoding = jax.nn.one_hot(jnp.array([label]), self.n_classes)\n",
    "        return optax.softmax_cross_entropy(val, label_one_hot_encoding)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(1/2 * jnp.tanh(w) + 1/2 - x)\n",
    "        penalty = self.c * self.f(1/2 * jnp.tanh(w) + 1/2, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x):\n",
    "        corrupted_x = x + w\n",
    "        # corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "        norm_grad = 2 * (corrupted_x - x)\n",
    "        # norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != self.true_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = val[self.true_label] - max_logit\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[self.true_label] - grad_model[max_label]\n",
    "        \n",
    "        return jnp.sum(norm_grad + self.c * penalty_grad)\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        x = jax.device_put(x)\n",
    "        self.true_label = self.get_label(x)\n",
    "        # use adam optimizer to find minimum of the problem\n",
    "        w = jnp.zeros_like(x)\n",
    "        optimizer = optax.adam(learning_rate=self.learning_rate)\n",
    "        state = optimizer.init(jax.device_put(w))\n",
    "        for i in range(self.max_iter):\n",
    "            corrupted_x = x.copy()\n",
    "            grad = self.get_obj_grad(w, x)\n",
    "            # grad = jax.grad(self.get_objective)(w, x, label)\n",
    "            # print(\"grad norm : \", np.linalg.norm(grad))\n",
    "\n",
    "            updates, state = optimizer.update(grad, state)\n",
    "            w = optax.apply_updates(jax.device_put(w), updates)\n",
    "            # w = w - self.learning_rate * grad\n",
    "            # corrupted_x = 1/2 * (jnp.tanh(w) + 1)\n",
    "            corrupted_x = x + w\n",
    "            corrupted_x = self.project_to_bounds(corrupted_x)\n",
    "            \n",
    "        # check if the attack was successful\n",
    "        new_label = self.get_label(corrupted_x)\n",
    "        if new_label == self.true_label:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "        else:\n",
    "            perturbation_norm = jnp.linalg.norm(corrupted_x - x)/jnp.linalg.norm(x)\n",
    "\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:33<2:34:28, 93.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [03:03<2:29:36, 91.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [04:34<2:27:04, 90.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [06:02<2:24:12, 90.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [07:28<2:20:03, 88.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [08:33<2:42:27, 102.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m all_xs, true_labels, epsilons, all_ys, K, test_key \u001b[38;5;241m=\u001b[39m init_data(test_key, n_samples\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[0;32m      4\u001b[0m corruption_model \u001b[38;5;241m=\u001b[39m untargeted_WG_Attack(model, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.10\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m perturbation_norms_WG \u001b[38;5;241m=\u001b[39m \u001b[43mget_average_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorruption_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m perturbation_norms_successful_WG \u001b[38;5;241m=\u001b[39m perturbation_norms_WG[perturbation_norms_WG \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m n_successful_WG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(perturbation_norms_successful_WG)\n",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mget_average_performance\u001b[1;34m(corruption_model, all_xs, epsilons, all_ys, K)\u001b[0m\n\u001b[0;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m all_xs[i]\n\u001b[0;32m      6\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m epsilons[i]\n\u001b[1;32m----> 7\u001b[0m     _, _, perturbation_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcorruption_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     perturbation_norms\u001b[38;5;241m.\u001b[39mappend(perturbation_norm)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(perturbation_norms)\n",
      "Cell \u001b[1;32mIn[9], line 86\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_perturbation\u001b[1;34m(self, x, epsilon, all_ys, K)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m     85\u001b[0m     corrupted_x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 86\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_obj_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# grad = jax.grad(self.get_objective)(w, x, label)\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# print(\"grad norm : \", np.linalg.norm(grad))\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     updates, state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grad, state)\n",
      "Cell \u001b[1;32mIn[9], line 58\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_obj_grad\u001b[1;34m(self, w, x)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# norm_grad = (1 - jnp.tanh(w)**2) * (corrupted_x - x)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_likelihoods(corrupted_x)\n\u001b[1;32m---> 58\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m max_label \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39margmax(val[jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_label])\n\u001b[0;32m     60\u001b[0m max_logit \u001b[38;5;241m=\u001b[39m val[max_label]\n",
      "Cell \u001b[1;32mIn[9], line 33\u001b[0m, in \u001b[0;36muntargeted_WG_Attack.get_gradients\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 33\u001b[0m     J \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m J\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mget_model_jacobian\u001b[1;34m(x, epsilon, y, K)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_jacobian\u001b[39m(x, epsilon, y, K):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_model_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:941\u001b[0m, in \u001b[0;36mjacrev.<locals>.jacfun\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    939\u001b[0m tree_map(partial(_check_input_dtype_jacrev, holomorphic, allow_int), dyn_args)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m--> 941\u001b[0m   y, pullback \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    943\u001b[0m   y, pullback, aux \u001b[38;5;241m=\u001b[39m _vjp(f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:2223\u001b[0m, in \u001b[0;36m_vjp\u001b[1;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m   2222\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[1;32m-> 2223\u001b[0m   out_primal, out_vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2225\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[0;32m   2226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:142\u001b[0m, in \u001b[0;36mvjp\u001b[1;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(traceable, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, reduce_axes\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m--> 142\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:131\u001b[0m, in \u001b[0;36mlinearize\u001b[1;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[0;32m    130\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[1;32m--> 131\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\partial_eval.py:774\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[1;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[38;5;241m=\u001b[39mcurrent_name_stack) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[0;32m    773\u001b[0m   fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[1;32m--> 774\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[0;32m    776\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m, in \u001b[0;36mget_model_output\u001b[1;34m(x, epsilon, y, K)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_output\u001b[39m(x, epsilon, y, K):\n\u001b[0;32m     29\u001b[0m     z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[0;32m     30\u001b[0m             partial(model\u001b[38;5;241m.\u001b[39mapply, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: trained_params}, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     31\u001b[0m             in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m         )(x, y, epsilon)\n\u001b[1;32m---> 34\u001b[0m     ll \u001b[38;5;241m=\u001b[39m \u001b[43mlog_likelyhood_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_q_z_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_p_x_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_p_y_xz\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(model\u001b[38;5;241m.\u001b[39mn_classes, K)\n\u001b[0;32m     37\u001b[0m     ll \u001b[38;5;241m=\u001b[39m logsumexp(ll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(K)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ll\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\code\\models\\ClassifierDFZ.py:147\u001b[0m, in \u001b[0;36mlog_likelyhood_A\u001b[1;34m(z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_likelyhood_A\u001b[39m(z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz):\n\u001b[1;32m--> 147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[43mloss_A\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_q_z_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_p_x_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_p_y_xz\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:1258\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1255\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1256\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 1258\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\code\\models\\ClassifierDFZ.py:123\u001b[0m, in \u001b[0;36mloss_A_single\u001b[1;34m(z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_A_single\u001b[39m(z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz):\n\u001b[1;32m--> 123\u001b[0m     logit_prior_z \u001b[38;5;241m=\u001b[39m \u001b[43mlog_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     ll \u001b[38;5;241m=\u001b[39m logit_p_x_z \u001b[38;5;241m+\u001b[39m logit_p_y_xz \u001b[38;5;241m+\u001b[39m logit_prior_z \u001b[38;5;241m-\u001b[39m logit_q_z_xy\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mll\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\code\\models\\utils.py:8\u001b[0m, in \u001b[0;36mlog_gaussian\u001b[1;34m(x, mu, logsigma)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_gaussian\u001b[39m(x, mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, logsigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[0;32m      7\u001b[0m     delta \u001b[38;5;241m=\u001b[39m ((x \u001b[38;5;241m-\u001b[39m mu) \u001b[38;5;241m/\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexp(logsigma))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogsigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39msum(logits)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:743\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 743\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:257\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 257\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr \u001b[38;5;241m=\u001b[39m _python_pjit_helper(\n\u001b[0;32m    258\u001b[0m       fun, infer_params_fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    259\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[0;32m    260\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(executable, out_tree, args_flat, out_flat)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:168\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[1;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m   dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m pjit_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\batching.py:433\u001b[0m, in \u001b[0;36mBatchTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    431\u001b[0m   frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_frame(vals_in, dims_in)\n\u001b[0;32m    432\u001b[0m   batched_primitive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_primitive_batcher(primitive, frame)\n\u001b[1;32m--> 433\u001b[0m   val_out, dim_out \u001b[38;5;241m=\u001b[39m batched_primitive(vals_in, dims_in, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    434\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1490\u001b[0m, in \u001b[0;36m_pjit_batcher\u001b[1;34m(insert_axis, spmd_axis_name, axis_size, axis_name, main_type, vals_in, dims_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline)\u001b[0m\n\u001b[0;32m   1482\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m   1483\u001b[0m     _pjit_batcher_for_sharding(i, axis_in, new_parts, mesh, aval\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m i\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis_in, i, aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dims_in, in_shardings, new_jaxpr\u001b[38;5;241m.\u001b[39min_avals))\n\u001b[0;32m   1486\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m   1487\u001b[0m     _pjit_batcher_for_sharding(o, axis_out, new_parts, mesh, aval\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m o\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis_out, o, aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes_out, out_shardings, new_jaxpr\u001b[38;5;241m.\u001b[39mout_avals))\n\u001b[1;32m-> 1490\u001b[0m vals_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m  \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m  \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1500\u001b[0m resolved_axes_out \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mresolve_ragged_axes_against_inputs_outputs(\n\u001b[0;32m   1501\u001b[0m     vals_in, vals_out, axes_out)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals_out, resolved_axes_out\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:318\u001b[0m, in \u001b[0;36mJVPTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifferentiation rule for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprimitive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m--> 318\u001b[0m primal_out, tangent_out \u001b[38;5;241m=\u001b[39m jvp(primals_in, tangents_in, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n\u001b[0;32m    320\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [JVPTracer(\u001b[38;5;28mself\u001b[39m, x, t) \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primal_out, tangent_out)]\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1558\u001b[0m, in \u001b[0;36m_pjit_jvp\u001b[1;34m(primals_in, tangents_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline)\u001b[0m\n\u001b[0;32m   1556\u001b[0m _filter_zeros_in \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_in)\n\u001b[0;32m   1557\u001b[0m _filter_zeros_out \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_out)\n\u001b[1;32m-> 1558\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr_jvp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1569\u001b[0m primals_out, tangents_out \u001b[38;5;241m=\u001b[39m split_list(outputs, [\u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)])\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\interpreters\\partial_eval.py:212\u001b[0m, in \u001b[0;36mJaxprTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m    211\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m primitive \u001b[38;5;129;01min\u001b[39;00m custom_partial_eval_rules:\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m custom_partial_eval_rules[primitive](\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_process_primitive(primitive, tracers, params)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1635\u001b[0m, in \u001b[0;36m_pjit_partial_eval\u001b[1;34m(trace, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *in_tracers)\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;66;03m# Bind known things to pjit_p.\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m known_inputs \u001b[38;5;241m=\u001b[39m [pv\u001b[38;5;241m.\u001b[39mget_known() \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals \u001b[38;5;28;01mif\u001b[39;00m pv\u001b[38;5;241m.\u001b[39mis_known()]\n\u001b[1;32m-> 1635\u001b[0m all_known_outs \u001b[38;5;241m=\u001b[39m pjit_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39mknown_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mknown_params)\n\u001b[0;32m   1636\u001b[0m all_known_outs \u001b[38;5;241m=\u001b[39m subs_list2(in_fwd, out_fwd, known_inputs, all_known_outs,\n\u001b[0;32m   1637\u001b[0m                             all_known_outs)\n\u001b[0;32m   1639\u001b[0m known_out_vals, residual_vals \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m   1640\u001b[0m     split_list(all_known_outs, [\u001b[38;5;28mlen\u001b[39m(all_known_outs) \u001b[38;5;241m-\u001b[39m num_residuals])\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\pjit.py:1245\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[1;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[0;32m   1242\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d]\n\u001b[0;32m   1243\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[0;32m   1244\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = untargeted_WG_Attack(model, max_iter=100, learning_rate=0.01, c = 0.10, p=2)\n",
    "\n",
    "perturbation_norms_WG = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_WG = perturbation_norms_WG[perturbation_norms_WG != -1]\n",
    "n_successful_WG = len(perturbation_norms_successful_WG)\n",
    "n_successful_WG\n",
    "print(f'Average perturbation norm of Wagner & Carlini Attack model (on {n_successful_WG} successful samples): {np.mean(perturbation_norms_successful_WG):>.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(range(n_samples))\n",
    "x = all_xs[i]\n",
    "true_label = true_labels[i]\n",
    "test_key, epsilons = sample_gaussian(test_key, (1, model.n_classes * K, model.d_latent))\n",
    "epsilon = epsilons[0]\n",
    "\n",
    "corruption_model = untargeted_WG_Attack(model, max_iter=100, learning_rate=0.0001, c = 0.1, p=2)\n",
    "corrupted_x, new_label, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[0].set_title(f\"Original image (label = '{map_label_to_name(true_label)}')\")\n",
    "\n",
    "axs[1].imshow(corrupted_x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[1].set_title(f\"Carlini and Wagner perturbated image (label = '{map_label_to_name(new_label)}')\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
