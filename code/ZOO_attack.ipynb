{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\orbax\\checkpoint\\type_handlers.py:1346: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "import os\n",
    "from ml_collections import ConfigDict\n",
    "from pathlib import Path\n",
    "from utils import prepare_test_dataset\n",
    "from dataset_utils import get_dataset\n",
    "from jax import random\n",
    "from models.utils import sample_gaussian\n",
    "\n",
    "import models.ClassifierGFZ as ClassifierGFZ\n",
    "import models.ClassifierDFZ as ClassifierDFZ\n",
    "\n",
    "checkpoint_path = \"dfz-2-epochs-first-try-1\"\n",
    "path = os.path.join(Path.cwd(), Path(f\"checkpoints\"), Path(checkpoint_path))\n",
    "checkpoint = ocp.PyTreeCheckpointer().restore(path, item=None)\n",
    "\n",
    "config = ConfigDict(checkpoint[\"config\"])\n",
    "dataset_config = ConfigDict(checkpoint[\"dataset_config\"])\n",
    "\n",
    "if config.model_name == \"GFZ\":\n",
    "    classifier = ClassifierGFZ\n",
    "elif config.model_name == \"DFZ\":\n",
    "    classifier = ClassifierDFZ\n",
    "else:\n",
    "    raise NotImplementedError(config.model_name)\n",
    "\n",
    "_, test_ds = get_dataset(config.dataset)\n",
    "test_images, test_labels = prepare_test_dataset(\n",
    "    test_ds, dataset_config\n",
    "    )\n",
    "\n",
    "trained_params = checkpoint[\"params\"]\n",
    "\n",
    "log_likelyhood_fn = classifier.log_likelyhood_A\n",
    "\n",
    "test_key = random.PRNGKey(config.seed)\n",
    "\n",
    "test_key, model, _ = classifier.create_and_init(\n",
    "    test_key, config, dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import jacrev\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def init_data(test_key, n_samples=10):\n",
    "    idx = np.random.choice(range(len(test_images)), n_samples, replace=False)\n",
    "\n",
    "    all_xs = test_images[idx]\n",
    "    true_ys = test_labels[idx]\n",
    "    true_labels = np.argmax(true_ys, axis=1)\n",
    "\n",
    "    K = model.K\n",
    "    batch_size = n_samples\n",
    "    test_key, epsilons = sample_gaussian(test_key, (batch_size, model.n_classes * K, model.d_latent))\n",
    "    epsilons = epsilons[:n_samples*model.n_classes]\n",
    "    all_ys = nn.one_hot(jnp.repeat(jnp.arange(model.n_classes), K), model.n_classes, dtype=jnp.float32)\n",
    "    \n",
    "    return all_xs, true_labels, epsilons, all_ys, K, test_key\n",
    "\n",
    "def get_model_output(x, epsilon, y, K):\n",
    "    z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz = jax.vmap(\n",
    "            partial(model.apply, {'params': trained_params}, train=False),\n",
    "            in_axes=(None, 0, 0)\n",
    "        )(x, y, epsilon)\n",
    "\n",
    "    ll = log_likelyhood_fn(\n",
    "            z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz\n",
    "        ).reshape(model.n_classes, K)\n",
    "    ll = logsumexp(ll, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def get_model_jacobian(x, epsilon, y, K):\n",
    "    return jacrev(get_model_output, argnums=0)(x, epsilon, y, K)\n",
    "\n",
    "def map_label_to_name(y):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeroth order optimization attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class ZOO_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c=1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x, epsilon=1e-5):\n",
    "        # Estimate gradients using finite differences\n",
    "        perturbed_x_plus = x + epsilon\n",
    "        perturbed_x_minus = x - epsilon\n",
    "\n",
    "        output_plus = self.get_likelihoods(perturbed_x_plus)\n",
    "        output_minus = self.get_likelihoods(perturbed_x_minus)\n",
    "\n",
    "        gradients = (output_plus - output_minus) / (2 * epsilon)\n",
    "\n",
    "        return gradients\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        x = self.project_to_bounds(x)\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(w)\n",
    "        penalty = self.c * self.f(x + w, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x, target_label):\n",
    "        # Compute gradient of the objective function\n",
    "        corrupted_x = x + w\n",
    "        norm_grad = (2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != target_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = max_logit - val[target_label]\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[max_label] - grad_model[target_label]\n",
    "        \n",
    "        return norm_grad + self.c * penalty_grad\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = jnp.zeros_like(x)\n",
    "        # for label in range(self.n_classes): # to do : optimize this loop\n",
    "        for label in range(self.n_classes): # to do : optimize this loop\n",
    "            if label != true_label:\n",
    "                w = jnp.zeros_like(x)\n",
    "                # use gradient descent to find minimum of the problem\n",
    "                for i in tqdm(range(self.max_iter)):\n",
    "                    grad = self.get_obj_grad(w, x, label)\n",
    "                    w = w - self.learning_rate * grad\n",
    "                    corrupted_x = x + w\n",
    "                    corrupted_x = self.project_to_bounds(corrupted_x)\n",
    "                    if self.get_label(corrupted_x) == label:\n",
    "                        break\n",
    "                    \n",
    "                # check if the attack was successful\n",
    "                new_label = self.get_label(corrupted_x)\n",
    "                if new_label != label:\n",
    "                    print(\"Warning: did not find a perturbation for this label\")\n",
    "                    perturbation_norm = -1\n",
    "                else:\n",
    "                    perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "                    print(\"Found a perturbation for label\", label, \"with norm\", perturbation_norm)\n",
    "                    print(corrupted_x)\n",
    "\n",
    "                # Choose minimal perturbation\n",
    "                if max_perturbation_norm == -1 and perturbation_norm != -1:\n",
    "                    max_perturbation_norm = perturbation_norm\n",
    "                    best_label = new_label\n",
    "                    best_corrupted_x = corrupted_x\n",
    "                else : \n",
    "                    if perturbation_norm != -1 and perturbation_norm < max_perturbation_norm:\n",
    "                        max_perturbation_norm = perturbation_norm\n",
    "                        best_label = new_label\n",
    "                        best_corrupted_x = corrupted_x\n",
    "\n",
    "        return best_corrupted_x, best_label, max_perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeroth order optimization attack\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "class ZOO_Attack():\n",
    "    def __init__(self, model, max_iter=10, learning_rate=0.1, c=1, p=2):\n",
    "        self.model = model\n",
    "        self.n_classes = model.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.c = c\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p / (self.p - 1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return jnp.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return jnp.argmax(val)\n",
    "\n",
    "    def get_likelihoods(self, x):\n",
    "        val = get_model_output(x, self.epsilon, self.y, self.K)\n",
    "        return val\n",
    "\n",
    "    def get_gradients(self, x, epsilon=1e-5):\n",
    "        # Estimate gradients using finite differences\n",
    "        perturbed_x_plus = x + epsilon\n",
    "        perturbed_x_minus = x - epsilon\n",
    "\n",
    "        output_plus = self.get_likelihoods(perturbed_x_plus)\n",
    "        output_minus = self.get_likelihoods(perturbed_x_minus)\n",
    "\n",
    "        gradients = (output_plus - output_minus) / (2 * epsilon)\n",
    "\n",
    "        return gradients\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "    \n",
    "    def f(self, x, target_label, k = 0):\n",
    "        x = self.project_to_bounds(x)\n",
    "        val = self.get_likelihoods(x)\n",
    "        max_logit = jnp.max(val[jnp.arange(self.n_classes) != target_label])\n",
    "        logit_diff = jnp.maximum(max_logit - val[target_label], - k)\n",
    "        return logit_diff\n",
    "    \n",
    "    def get_objective(self, w, x, target_label, k = 0):\n",
    "        norm = self.qnorm(w)\n",
    "        penalty = self.c * self.f(x + w, target_label, k = k)\n",
    "        return norm + penalty\n",
    "    \n",
    "    def get_obj_grad(self, w, x, target_label):\n",
    "        # Compute gradient of the objective function\n",
    "        corrupted_x = x + w\n",
    "        norm_grad = (2) * (corrupted_x - x)\n",
    "\n",
    "        val = self.get_likelihoods(corrupted_x)\n",
    "        grad_model = self.get_gradients(corrupted_x)\n",
    "        max_label = jnp.argmax(val[jnp.arange(self.n_classes) != target_label])\n",
    "        max_logit = val[max_label]\n",
    "        logit_diff = max_logit - val[target_label]\n",
    "        if logit_diff <= 0:\n",
    "            penalty_grad = 0\n",
    "        else:\n",
    "            penalty_grad = grad_model[max_label] - grad_model[target_label]\n",
    "        \n",
    "        return norm_grad + self.c * penalty_grad\n",
    "    \n",
    "    def project_to_bounds(self, x):\n",
    "        bounds_min = jnp.zeros_like(x)\n",
    "        bounds_max = jnp.ones_like(x)\n",
    "        return jnp.clip(x, bounds_min, bounds_max)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        self.y = all_ys\n",
    "        self.epsilon = epsilon\n",
    "        self.K = K\n",
    "        true_label = self.get_label(x)\n",
    "        max_perturbation_norm = -1\n",
    "        best_label = true_label\n",
    "        best_corrupted_x = jnp.zeros_like(x)\n",
    "        # for label in range(self.n_classes): # to do : optimize this loop\n",
    "        w = jnp.zeros_like(x)\n",
    "        # use gradient descent to find minimum of the problem\n",
    "        for i in tqdm(range(self.max_iter)):\n",
    "            grad = self.get_obj_grad(w, x)\n",
    "            w = w - self.learning_rate * grad\n",
    "            corrupted_x = x + w\n",
    "            corrupted_x = self.project_to_bounds(corrupted_x)\n",
    "            if self.get_label(corrupted_x) == label:\n",
    "                break\n",
    "            \n",
    "        # check if the attack was successful\n",
    "        new_label = self.get_label(corrupted_x)\n",
    "        if new_label != label:\n",
    "            print(\"Warning: did not find a perturbation for this label\")\n",
    "            perturbation_norm = -1\n",
    "        else:\n",
    "            perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "            print(\"Found a perturbation for label\", label, \"with norm\", perturbation_norm)\n",
    "            print(corrupted_x)\n",
    "\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "Argmax indices for each column (excluding diagonal): [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_argmax_except_diagonal(matrix):\n",
    "    # Create an array of column indices\n",
    "    matrix = np.array([matrix for i in range(matrix.shape[0])])\n",
    "    matrix = np.transpose(matrix)\n",
    "    col_indices = np.arange(matrix.shape[1])\n",
    "    values = matrix[np.arange(matrix.shape[1]), np.arange(matrix.shape[1])]\n",
    "    mask = col_indices[:, np.newaxis] == np.arange(matrix.shape[0])\n",
    "    matrix[mask] = np.min(matrix) - 1\n",
    "    argmax_indices = np.argmax(matrix, axis=1)\n",
    "    max_logits = matrix[argmax_indices, np.arange(matrix.shape[1])]\n",
    "\n",
    "    diff = max_logits - values\n",
    "    print((diff>0)*1)\n",
    "\n",
    "    return argmax_indices\n",
    "\n",
    "# Example usage:\n",
    "matrix = np.array([1, 2, 3])\n",
    "\n",
    "argmax_indices = find_argmax_except_diagonal(matrix)\n",
    "print(\"Argmax indices for each column (excluding diagonal):\", argmax_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_performance(corruption_model, all_xs, epsilons, all_ys, K):\n",
    "    perturbation_norms = []\n",
    "    n_samples = len(all_xs)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        x = all_xs[i]\n",
    "        epsilon = epsilons[i]\n",
    "        _, _, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "        perturbation_norms.append(perturbation_norm)\n",
    "    return np.array(perturbation_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation for this label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation for this label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation for this label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "n_samples = 1\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = ZOO_Attack(model, max_iter=10, learning_rate=0.1, c=1, p=2)\n",
    "\n",
    "perturbation_norms_ZOO = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_ZOO = perturbation_norms_ZOO[perturbation_norms_ZOO != -1]\n",
    "n_successful_ZOO = len(perturbation_norms_successful_ZOO)\n",
    "n_successful_ZOO\n",
    "print(f'Average perturbation norm of ZOO Attack model (on {n_successful_ZOO} successful samples): {np.mean(perturbation_norms_successful_ZOO):>.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:05<01:38,  1.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m epsilons[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m corruption_model \u001b[38;5;241m=\u001b[39m ZOO_Attack(model, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m corrupted_x, new_label, perturbation_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcorruption_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     12\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 97\u001b[0m, in \u001b[0;36mZOO_Attack.get_perturbation\u001b[1;34m(self, x, epsilon, all_ys, K)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# use gradient descent to find minimum of the problem\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)):\n\u001b[1;32m---> 97\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_obj_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m grad\n\u001b[0;32m     99\u001b[0m     corrupted_x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m w\n",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m, in \u001b[0;36mZOO_Attack.get_obj_grad\u001b[1;34m(self, w, x, target_label)\u001b[0m\n\u001b[0;32m     63\u001b[0m corrupted_x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m w\n\u001b[0;32m     64\u001b[0m norm_grad \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m (corrupted_x \u001b[38;5;241m-\u001b[39m x)\n\u001b[1;32m---> 66\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_likelihoods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gradients(corrupted_x)\n\u001b[0;32m     68\u001b[0m max_label \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39margmax(val[jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes) \u001b[38;5;241m!=\u001b[39m target_label])\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mZOO_Attack.get_likelihoods\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_likelihoods\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 29\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m, in \u001b[0;36mget_model_output\u001b[1;34m(x, epsilon, y, K)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_output\u001b[39m(x, epsilon, y, K):\n\u001b[1;32m---> 29\u001b[0m     z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     ll \u001b[38;5;241m=\u001b[39m log_likelyhood_fn(\n\u001b[0;32m     35\u001b[0m             z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz\n\u001b[0;32m     36\u001b[0m         )\u001b[38;5;241m.\u001b[39mreshape(model\u001b[38;5;241m.\u001b[39mn_classes, K)\n\u001b[0;32m     37\u001b[0m     ll \u001b[38;5;241m=\u001b[39m logsumexp(ll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(K)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\api.py:1258\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1255\u001b[0m in_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap in_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_tree, (in_axes, \u001b[38;5;241m0\u001b[39m), kws\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1256\u001b[0m axis_size_ \u001b[38;5;241m=\u001b[39m (axis_size \u001b[38;5;28;01mif\u001b[39;00m axis_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m               _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 1258\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspmd_axis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspmd_axis_name\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree(), out_flat)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:1911\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1909\u001b[0m   method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m\n\u001b[0;32m   1910\u001b[0m method \u001b[38;5;241m=\u001b[39m _get_unbound_fn(method)\n\u001b[1;32m-> 1911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply(\n\u001b[0;32m   1912\u001b[0m     method,\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1914\u001b[0m     mutable\u001b[38;5;241m=\u001b[39mmutable,\n\u001b[0;32m   1915\u001b[0m     capture_intermediates\u001b[38;5;241m=\u001b[39mcapture_intermediates,\n\u001b[0;32m   1916\u001b[0m )(variables, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, rngs\u001b[38;5;241m=\u001b[39mrngs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\core\\scope.py:1080\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[1;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1075\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bind(\n\u001b[0;32m   1078\u001b[0m     variables, rngs\u001b[38;5;241m=\u001b[39mrngs, mutable\u001b[38;5;241m=\u001b[39mmutable, flags\u001b[38;5;241m=\u001b[39mflags\n\u001b[0;32m   1079\u001b[0m )\u001b[38;5;241m.\u001b[39mtemporary() \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m-> 1080\u001b[0m   y \u001b[38;5;241m=\u001b[39m fn(root, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mutable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y, root\u001b[38;5;241m.\u001b[39mmutable_variables()\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:2572\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[1;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2570\u001b[0m _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mappend(capture_intermediates)\n\u001b[0;32m   2571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2572\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(module\u001b[38;5;241m.\u001b[39mclone(parent\u001b[38;5;241m=\u001b[39mscope, _deep_clone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2573\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2574\u001b[0m   _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[0;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[1;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[0;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[1;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\code\\models\\ClassifierDFZ.py:40\u001b[0m, in \u001b[0;36mClassifierDFZ.__call__\u001b[1;34m(self, X, y, epsilon, train)\u001b[0m\n\u001b[0;32m     28\u001b[0m z, logit_q_z_xy \u001b[38;5;241m=\u001b[39m Log_q_z_xy(\n\u001b[0;32m     29\u001b[0m     n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes,\n\u001b[0;32m     30\u001b[0m     d_latent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_latent,\n\u001b[0;32m     31\u001b[0m     d_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_hidden,\n\u001b[0;32m     32\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate,\n\u001b[0;32m     33\u001b[0m )(X, y, epsilon, train)\n\u001b[0;32m     34\u001b[0m logit_p_x_z \u001b[38;5;241m=\u001b[39m Log_p_x_z(\n\u001b[0;32m     35\u001b[0m     n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes,\n\u001b[0;32m     36\u001b[0m     d_latent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_latent,\n\u001b[0;32m     37\u001b[0m     d_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_hidden,\n\u001b[0;32m     38\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate,\n\u001b[0;32m     39\u001b[0m )(X, z, train)\n\u001b[1;32m---> 40\u001b[0m logit_p_y_xz \u001b[38;5;241m=\u001b[39m \u001b[43mLog_p_y_xz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_latent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_latent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_hidden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, logit_q_z_xy, logit_p_x_z, logit_p_y_xz\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[0;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[1;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[0;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[1;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\code\\models\\Log_p_y_xz.py:22\u001b[0m, in \u001b[0;36mLog_p_y_xz.__call__\u001b[1;34m(self, X, y, z, train)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, z, train: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# X: (height, width), y: (n_classes,), prior: (d_latent,) -> (d_latent,), 0\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_convolutions):\n\u001b[1;32m---> 22\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkernel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglorot_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m         X \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mrelu(X)\n\u001b[0;32m     30\u001b[0m     X_flatten \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[0;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[1;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[0;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[1;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\flax\\linen\\linear.py:529\u001b[0m, in \u001b[0;36m_Conv.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    527\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    528\u001b[0m     conv_general_dilated \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mconv_general_dilated\n\u001b[1;32m--> 529\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mconv_general_dilated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding_lax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_dilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfeature_group_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_group_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m   y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mconv_general_dilated_local(\n\u001b[0;32m    542\u001b[0m       lhs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    543\u001b[0m       rhs\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m       precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision,\n\u001b[0;32m    551\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\lax\\convolution.py:161\u001b[0m, in \u001b[0;36mconv_general_dilated\u001b[1;34m(lhs, rhs, window_strides, padding, lhs_dilation, rhs_dilation, dimension_numbers, feature_group_count, batch_group_count, precision, preferred_element_type)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    155\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadding argument to conv_general_dilated should be a string or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence of (low, high) pairs, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    158\u001b[0m preferred_element_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m preferred_element_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(np\u001b[38;5;241m.\u001b[39mdtype(preferred_element_type)))\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv_general_dilated_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_strides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwindow_strides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlhs_dilation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrhs_dilation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_group_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_group_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_group_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_group_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:444\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    442\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    443\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[1;32m--> 444\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Manal\\Desktop\\3A\\PGM\\adversarial-attacks-on-generative-classifiers\\.venv\\lib\\site-packages\\jax\\_src\\dispatch.py:87\u001b[0m, in \u001b[0;36mapply_primitive\u001b[1;34m(prim, *args, **params)\u001b[0m\n\u001b[0;32m     85\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = np.random.choice(range(n_samples))\n",
    "x = all_xs[i]\n",
    "true_label = true_labels[i]\n",
    "test_key, epsilons = sample_gaussian(test_key, (1, model.n_classes * K, model.d_latent))\n",
    "epsilon = epsilons[0]\n",
    "\n",
    "corruption_model = ZOO_Attack(model, max_iter=100, learning_rate=0.1, c = 10, p=2)\n",
    "corrupted_x, new_label, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[0].set_title(f\"Original image (label = '{map_label_to_name(true_label)}')\")\n",
    "\n",
    "axs[1].imshow(corrupted_x.reshape(28, 28), cmap=\"gray\")\n",
    "axs[1].set_title(f\"ZOO perturbated image (label = '{map_label_to_name(new_label)}')\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.840046\n"
     ]
    }
   ],
   "source": [
    "print(jnp.linalg.norm(x - corrupted_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.02352941]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.20392157]]\n"
     ]
    }
   ],
   "source": [
    "print(x[0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(corrupted_x[0,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
