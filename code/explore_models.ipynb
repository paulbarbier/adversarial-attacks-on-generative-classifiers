{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import ConfigDict\n",
    "from pathlib import Path\n",
    "from utils import get_classifier, get_data_config, get_dtype, load_checkpoint, prepare_test_dataset\n",
    "from dataset_utils import get_dataloader, get_dataset\n",
    "from jax import random\n",
    "from models.utils import sample_gaussian\n",
    "\n",
    "checkpoint_path = \"dfz-50-epochs-a-1\"\n",
    "\n",
    "checkpoint = load_checkpoint(Path.cwd() / \"checkpoints/modified/\" / checkpoint_path)\n",
    "\n",
    "config = ConfigDict(checkpoint[\"config\"])\n",
    "\n",
    "dtype = get_dtype(config.dtype)\n",
    "test_key = random.PRNGKey(config.attack_seed)\n",
    "classifier = get_classifier(config) \n",
    "\n",
    "test_ds = get_dataset(config.dataset, train=False)\n",
    "dataset_config = get_data_config(test_ds)\n",
    "test_images, test_labels = prepare_test_dataset(test_ds, dataset_config, dtype)\n",
    "\n",
    "test_dl = get_dataloader(test_ds, config.test_batch_size, dtype)\n",
    "\n",
    "model_config = classifier.create_model_config(config)\n",
    "log_likelihood_fn = classifier.log_likelihood_A\n",
    "loss_fn = classifier.loss_A\n",
    "trained_params = checkpoint[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import jacrev\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def init_data(test_key, n_samples=10):\n",
    "    idx = np.random.choice(range(len(test_images)), n_samples, replace=False)\n",
    "\n",
    "    all_xs = test_images[idx]\n",
    "    true_ys = test_labels[idx]\n",
    "    true_labels = np.argmax(true_ys, axis=1)\n",
    "\n",
    "    K = model_config.K\n",
    "    batch_size = n_samples\n",
    "    test_key, epsilons = sample_gaussian(test_key, (batch_size, model_config.n_classes * K, model_config.d_latent))\n",
    "    epsilons = epsilons[:n_samples*model_config.n_classes]\n",
    "    all_ys = nn.one_hot(jnp.repeat(jnp.arange(model_config.n_classes), K), model_config.n_classes, dtype=dtype)\n",
    "    \n",
    "    return all_xs, true_labels, epsilons, all_ys, K, test_key\n",
    "\n",
    "def get_model_output(x, epsilon, y, K):\n",
    "    outputs = jax.vmap(\n",
    "            partial(classifier.classifier(model_config).apply, {'params': trained_params}, train=False),\n",
    "            in_axes=(None, 0, 0)\n",
    "        )(x, y, epsilon)\n",
    "\n",
    "    ll = log_likelihood_fn(*outputs).reshape(config.n_classes, K)\n",
    "    ll = logsumexp(ll, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def get_model_jacobian(x, epsilon, y, K):\n",
    "    return jacrev(get_model_output, argnums=0)(x, epsilon, y, K)\n",
    "\n",
    "def map_label_to_name(y):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To script : currently takes 1 sample x, 1 generated epsilon, all_y and K to generate 1 perturbation\n",
    "## Maybe: make it work for batch samples?\n",
    "\n",
    "class DeepFool():\n",
    "    def __init__(self, config, max_iter=10, learning_rate=1, p=2):\n",
    "        self.config = config\n",
    "        self.n_classes = config.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p/(self.p-1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return np.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x, epsilon):\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return np.argmax(val)\n",
    "\n",
    "    def get_likelihoods_and_gradients(self, x, epsilon):\n",
    "        J = get_model_jacobian(x, epsilon, self.y, self.K)\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return val, J\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        corrupted_x = x.copy()\n",
    "        self.y = all_ys\n",
    "        self.K = K\n",
    "        new_label = self.get_label(corrupted_x, epsilon)\n",
    "        k = self.get_label(x, epsilon)\n",
    "        for _ in range(self.max_iter):\n",
    "            best_pert = np.inf\n",
    "            likelihoods, gradients = self.get_likelihoods_and_gradients(corrupted_x, epsilon)\n",
    "            for j in range(self.n_classes):\n",
    "                if j != k:\n",
    "                    w_j = gradients[j] - gradients[k]\n",
    "                    f_j = likelihoods[j] - likelihoods[k]\n",
    "                    pert = np.abs(f_j) / self.qnorm(w_j)\n",
    "                    if pert < best_pert:\n",
    "                        w = w_j\n",
    "                        f = f_j\n",
    "            r_i = (np.abs(f) / self.qnorm(w)**self.q) * (np.sign(w) * np.abs(w)**(self.q-1))\n",
    "            corrupted_x = corrupted_x + self.learning_rate*r_i\n",
    "            new_label = self.get_label(corrupted_x, epsilon)\n",
    "            if new_label != k:\n",
    "                break\n",
    "        if new_label == k:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "        else:\n",
    "            perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To script : currently takes 1 sample x, 1 generated epsilon, all_y and K to generate 1 perturbation\n",
    "## Maybe: make it work for batch samples?\n",
    "\n",
    "class FastGradientSign():\n",
    "    def __init__(self, eta=0.3):\n",
    "        self.eta = eta\n",
    "\n",
    "    def get_likelihoods_and_gradients(self, x, epsilon):\n",
    "        J = get_model_jacobian(x, epsilon, self.y, self.K)\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return val, J\n",
    "    \n",
    "    def get_label(self, x, epsilon):\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return np.argmax(val)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        corrupted_x = x.copy()  \n",
    "        self.y = all_ys\n",
    "        self.K = K\n",
    "        original_label = self.get_label(x, epsilon)\n",
    "        _, gradients = self.get_likelihoods_and_gradients(corrupted_x, epsilon)\n",
    "        perturbations = np.array([self.eta * np.sign(g) for g in gradients])\n",
    "        perturbated_labels = np.array([self.get_label(x+p, epsilon) for p in perturbations])\n",
    "        different_labels_ids = np.where(perturbated_labels != original_label)\n",
    "        if len(different_labels_ids[0]) == 0:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "            new_label = original_label\n",
    "            smallest_perturbation = np.argmin(np.linalg.norm(perturbations, axis=0))\n",
    "            corrupted_x = x + smallest_perturbation\n",
    "        else:\n",
    "            different_labels_norms = np.array([np.linalg.norm(p) for p in perturbations])[different_labels_ids]\n",
    "            corrupted_x = x + perturbations[np.argmin(different_labels_norms)]\n",
    "            new_label = self.get_label(corrupted_x, epsilon)\n",
    "            perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [02:06<01:12,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [02:27<00:24,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:38<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perturbation norm of DeepFool model (on 98 successful samples): 0.2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:31<03:45,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:58<03:10,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:19<02:51,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:59<02:11,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [02:12<02:01,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:17<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perturbation norm of Fast Gradient Sign model (on 95 successful samples): 0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Generalize to other models with same structure (self.get_perturbation() returns norm of perturbation)\n",
    "\n",
    "def get_average_performance(corruption_model, all_xs, epsilons, all_ys, K):\n",
    "    perturbation_norms = []\n",
    "    n_samples = len(all_xs)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        x = all_xs[i]\n",
    "        epsilon = epsilons[i]\n",
    "        _, _, perturbation_norm = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "        perturbation_norms.append(perturbation_norm)\n",
    "    return np.array(perturbation_norms)\n",
    "\n",
    "## DeepFool average performance on 100 samples\n",
    "n_samples = 100\n",
    "all_xs, true_labels, epsilons, all_ys, K, test_key = init_data(test_key, n_samples=n_samples)\n",
    "\n",
    "corruption_model = DeepFool(config)\n",
    "\n",
    "perturbation_norms_deepfool = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_deepfool = perturbation_norms_deepfool[perturbation_norms_deepfool != -1]\n",
    "n_successful_deepfool = len(perturbation_norms_successful_deepfool)\n",
    "\n",
    "print(f'Average perturbation norm of DeepFool model (on {n_successful_deepfool} successful samples): {np.mean(perturbation_norms_successful_deepfool):>.4f}')\n",
    "\n",
    "## Fast Gradient Sign average performance on 100 samples\n",
    "corruption_model = FastGradientSign(eta=0.3)\n",
    "\n",
    "perturbation_norms_fgs = get_average_performance(corruption_model, all_xs, epsilons, all_ys, K)\n",
    "perturbation_norms_successful_fgs = perturbation_norms_fgs[perturbation_norms_fgs != -1]\n",
    "n_successful_fgs = len(perturbation_norms_successful_fgs)\n",
    "\n",
    "print(f'Average perturbation norm of Fast Gradient Sign model (on {n_successful_fgs} successful samples): {np.mean(perturbation_norms_successful_fgs):>.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to implement (illustrative example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = np.random.choice(range(n_samples))\n",
    "# x = all_xs[i]\n",
    "# true_label = true_labels[i]\n",
    "# test_key, epsilons = sample_gaussian(test_key, (1, model.n_classes * K, model.d_latent))\n",
    "# epsilon = epsilons[0]\n",
    "\n",
    "# deepfool_model = DeepFool(model, learning_rate=0.2)\n",
    "# corrupted_x_deepfool, new_label_deepfool, perturbation_norm_deepfool = deepfool_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "# fgs_model = FastGradientSign(model, eta=0.2)\n",
    "# corrupted_x_fgs, new_label_fgs, perturbation_norm_fgs = fgs_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# axs[0].imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[0].set_title(f\"Original image (label = '{map_label_to_name(true_label)}')\")\n",
    "\n",
    "# axs[1].imshow(corrupted_x_deepfool.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[1].set_title(f\"DeepFool perturbated image (label = '{map_label_to_name(new_label_deepfool)}')\")\n",
    "\n",
    "# axs[2].imshow(corrupted_x_fgs.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[2].set_title(f\"FGS perturbated image (label = '{map_label_to_name(new_label_fgs)}')\")\n",
    "\n",
    "# fig.suptitle(f\"Comparison of DeepFool and Fast Gradient Sign on a random sample\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
