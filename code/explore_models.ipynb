{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import ConfigDict\n",
    "from pathlib import Path\n",
    "from utils import get_classifier, get_data_config, get_dtype, load_checkpoint, prepare_test_dataset\n",
    "from dataset_utils import get_dataloader, get_dataset\n",
    "from jax import random\n",
    "from models.utils import sample_gaussian\n",
    "\n",
    "checkpoint_path = \"gfz-50-epochs-a-1\"\n",
    "model_type = 'GFZ'\n",
    "\n",
    "checkpoint = load_checkpoint(Path.cwd() / \"checkpoints/modified/\" / checkpoint_path)\n",
    "\n",
    "config = ConfigDict(checkpoint[\"config\"])\n",
    "\n",
    "dtype = get_dtype(config.dtype)\n",
    "test_key = random.PRNGKey(config.attack_seed)\n",
    "classifier = get_classifier(config) \n",
    "\n",
    "test_ds = get_dataset(config.dataset, train=False)\n",
    "train_ds = get_dataset(config.dataset, train=True)\n",
    "dataset_config = get_data_config(test_ds)\n",
    "test_images, test_labels = prepare_test_dataset(test_ds, dataset_config, dtype)\n",
    "\n",
    "train_images, train_labels = prepare_test_dataset(train_ds, dataset_config, dtype)\n",
    "\n",
    "test_dl = get_dataloader(test_ds, config.test_batch_size, dtype)\n",
    "\n",
    "model_config = classifier.create_model_config(config)\n",
    "log_likelihood_fn = classifier.log_likelihood_A\n",
    "loss_fn = classifier.loss_A\n",
    "trained_params = checkpoint[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import jacrev\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax.scipy.special import logsumexp\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "def init_data(test_key, _type='test', n_samples=10):\n",
    "    if _type == 'test':\n",
    "        idx = np.random.choice(range(len(test_images)), n_samples, replace=False)\n",
    "        all_xs = test_images[idx]\n",
    "        true_ys = test_labels[idx]\n",
    "\n",
    "    elif _type == 'train':\n",
    "        idx = np.random.choice(range(len(train_images)), n_samples, replace=False)\n",
    "        all_xs = train_images[idx]\n",
    "        true_ys = train_labels[idx]\n",
    "\n",
    "    true_labels = np.argmax(true_ys, axis=1)\n",
    "\n",
    "    K = model_config.K\n",
    "    batch_size = n_samples\n",
    "    test_key, epsilons = sample_gaussian(test_key, (batch_size, model_config.n_classes * K, model_config.d_latent))\n",
    "    epsilons = epsilons[:n_samples*model_config.n_classes]\n",
    "    all_ys = nn.one_hot(jnp.repeat(jnp.arange(model_config.n_classes), K), model_config.n_classes, dtype=dtype)\n",
    "    \n",
    "    return all_xs, true_labels, epsilons, all_ys, K, test_key\n",
    "\n",
    "def get_model_output(x, epsilon, y, K, no_grad=False):\n",
    "    outputs = jax.vmap(\n",
    "            partial(classifier.classifier(model_config).apply, {'params': trained_params}, train=False),\n",
    "            in_axes=(None, 0, 0)\n",
    "        )(x, y, epsilon)\n",
    "\n",
    "    ll = log_likelihood_fn(*outputs).reshape(config.n_classes, K)\n",
    "    ll = logsumexp(ll, axis=1) - np.log(K)\n",
    "    return ll\n",
    "\n",
    "def get_model_jacobian(x, epsilon, y, K):\n",
    "    return jacrev(get_model_output, argnums=0)(x, epsilon, y, K, no_grad=False)\n",
    "\n",
    "def map_label_to_name(y):\n",
    "    labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "              \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "    return labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFool():\n",
    "    def __init__(self, config, max_iter=10, learning_rate=1, p=2):\n",
    "        self.config = config\n",
    "        self.n_classes = config.n_classes\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        assert p > 1 \n",
    "        self.p = p\n",
    "        if self.p == np.inf:\n",
    "            self.q = 1\n",
    "        else:\n",
    "            self.q = self.p/(self.p-1)\n",
    "\n",
    "    def qnorm(self, x):\n",
    "        return np.linalg.norm(x.flatten(), self.q)\n",
    "\n",
    "    def get_label(self, x, epsilon):\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return np.argmax(val)\n",
    "\n",
    "    def get_likelihoods_and_gradients(self, x, epsilon):\n",
    "        J = get_model_jacobian(x, epsilon, self.y, self.K)\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return val, J\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        corrupted_x = x.copy()\n",
    "        self.y = all_ys\n",
    "        self.K = K\n",
    "        new_label = self.get_label(corrupted_x, epsilon)\n",
    "        k = self.get_label(x, epsilon)\n",
    "        for _ in range(self.max_iter):\n",
    "            best_pert = np.inf\n",
    "            likelihoods, gradients = self.get_likelihoods_and_gradients(corrupted_x, epsilon)\n",
    "            for j in range(self.n_classes):\n",
    "                if j != k:\n",
    "                    w_j = gradients[j] - gradients[k]\n",
    "                    f_j = likelihoods[j] - likelihoods[k]\n",
    "                    pert = np.abs(f_j) / self.qnorm(w_j)\n",
    "                    if pert < best_pert:\n",
    "                        w = w_j\n",
    "                        f = f_j\n",
    "            r_i = (np.abs(f) / self.qnorm(w)**self.q) * (np.sign(w) * np.abs(w)**(self.q-1))\n",
    "            corrupted_x = corrupted_x + self.learning_rate*r_i\n",
    "            new_label = self.get_label(corrupted_x, epsilon)\n",
    "            if new_label != k:\n",
    "                break\n",
    "        if new_label == k:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "        else:\n",
    "            perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastGradientSign():\n",
    "    def __init__(self, eta=0.3):\n",
    "        self.eta = eta\n",
    "\n",
    "    def get_likelihoods_and_gradients(self, x, epsilon):\n",
    "        J = get_model_jacobian(x, epsilon, self.y, self.K)\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return val, J\n",
    "    \n",
    "    def get_label(self, x, epsilon):\n",
    "        val = get_model_output(x, epsilon, self.y, self.K)\n",
    "        return np.argmax(val)\n",
    "\n",
    "    def get_perturbation(self, x, epsilon, all_ys, K):\n",
    "        corrupted_x = x.copy()  \n",
    "        self.y = all_ys\n",
    "        self.K = K\n",
    "        original_label = self.get_label(x, epsilon)\n",
    "        _, gradients = self.get_likelihoods_and_gradients(corrupted_x, epsilon)\n",
    "        perturbations = np.array([self.eta * np.sign(g) for g in gradients])\n",
    "        perturbated_labels = np.array([self.get_label(x+p, epsilon) for p in perturbations])\n",
    "        different_labels_ids = np.where(perturbated_labels != original_label)\n",
    "        if len(different_labels_ids[0]) == 0:\n",
    "            print(\"Warning: did not find a perturbation\")\n",
    "            perturbation_norm = -1\n",
    "            new_label = original_label\n",
    "            smallest_perturbation = np.argmin(np.linalg.norm(perturbations, axis=0))\n",
    "            corrupted_x = x + smallest_perturbation\n",
    "        else:\n",
    "            different_labels_norms = np.array([np.linalg.norm(p) for p in perturbations])[different_labels_ids]\n",
    "            corrupted_x = x + perturbations[np.argmin(different_labels_norms)]\n",
    "            new_label = self.get_label(corrupted_x, epsilon)\n",
    "            perturbation_norm = np.linalg.norm(corrupted_x - x)/np.linalg.norm(x)\n",
    "        return corrupted_x, new_label, perturbation_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [02:06<01:12,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [02:27<00:24,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:38<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perturbation norm of DeepFool model (on 98 successful samples): 0.2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:31<03:45,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:58<03:10,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:19<02:51,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:59<02:11,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [02:12<02:01,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: did not find a perturbation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:17<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perturbation norm of Fast Gradient Sign model (on 95 successful samples): 0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# i = np.random.choice(range(n_samples))\n",
    "# x = all_xs[i]\n",
    "# true_label = true_labels[i]\n",
    "# test_key, epsilons = sample_gaussian(test_key, (1, model_config.n_classes * K, model_config.d_latent))\n",
    "# epsilon = epsilons[0]\n",
    "\n",
    "# deepfool_model = DeepFool(config, learning_rate=0.2)\n",
    "# corrupted_x_deepfool, new_label_deepfool, perturbation_norm_deepfool = deepfool_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "# fgs_model = FastGradientSign(eta=0.3)\n",
    "# corrupted_x_fgs, new_label_fgs, perturbation_norm_fgs = fgs_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# axs[0].imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[0].set_title(f\"Original image (label = '{map_label_to_name(true_label)}')\")\n",
    "\n",
    "# axs[1].imshow(corrupted_x_deepfool.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[1].set_title(f\"DeepFool perturbated image (label = '{map_label_to_name(new_label_deepfool)}')\")\n",
    "\n",
    "# axs[2].imshow(corrupted_x_fgs.reshape(28, 28), cmap=\"gray\")\n",
    "# axs[2].set_title(f\"FGS perturbated image (label = '{map_label_to_name(new_label_fgs)}')\")\n",
    "\n",
    "# fig.suptitle(f\"Comparison of DeepFool and Fast Gradient Sign on a random sample\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_p_bayes(corruption_model, n_samples, all_xs, epsilons, true_labels, all_ys, K, corruption=True):\n",
    "    all_generated_p_bayes = np.zeros((n_samples, 10))\n",
    "    well_classified = []\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        x = all_xs[i]\n",
    "        epsilon = epsilons[i]\n",
    "        if corruption:\n",
    "            corrupted_x, _, _ = corruption_model.get_perturbation(x, epsilon, all_ys, K)\n",
    "        else:\n",
    "            corrupted_x = x\n",
    "        ll = get_model_output(corrupted_x, epsilon, all_ys, K)\n",
    "        p_bayes = softmax(ll)\n",
    "        if true_labels[i] == np.argmax(p_bayes):\n",
    "            well_classified.append(i)\n",
    "        all_generated_p_bayes[i] = p_bayes\n",
    "    return all_generated_p_bayes, well_classified\n",
    "\n",
    "def evaluate_treshold(alpha, all_generated_p_bayes, generated_predictions, all_true_p_bayes, true_predictions, well_classified, means, stds, n_samples):\n",
    "    tresholds = means - alpha*stds\n",
    "\n",
    "    detections = 0\n",
    "    for i in range(n_samples):\n",
    "        p_bayes = all_generated_p_bayes[i]\n",
    "        if np.max(p_bayes) < tresholds[generated_predictions[i]]:\n",
    "            detections += 1\n",
    "    detection_rate = detections/n_samples\n",
    "\n",
    "    false_positives = 0\n",
    "    for i in well_classified:\n",
    "        p_bayes = all_true_p_bayes[i]\n",
    "        if np.max(p_bayes) < tresholds[true_predictions[i]]:\n",
    "            false_positives += 1\n",
    "    false_positive_rate = false_positives/len(well_classified)\n",
    "\n",
    "    return detection_rate, false_positive_rate\n",
    "\n",
    "def display_roc_curve(false_positives_list, detection_list, model_name, save=False):\n",
    "    plt.plot(false_positives_list, detection_list)\n",
    "    plt.xlabel(\"False positives\")\n",
    "    plt.ylabel(\"Detection rate\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f\"ROC curve - {model_name}\")\n",
    "    if save:\n",
    "        plt.savefig(f\"../latex/illustrations/ROC_{model_name}_{model_type}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(all_true_p_bayes, true_predictions, n_samples, n_classes):\n",
    "    values = {i:[] for i in range(n_classes)}\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        values[true_predictions[i]].append(all_true_p_bayes[i][true_predictions[i]])\n",
    "\n",
    "    means = np.array([np.mean(values[i]) for i in range(n_classes)])\n",
    "    stds = np.array([np.std(values[i]) for i in range(n_classes)])\n",
    "    return means, stds\n",
    "\n",
    "def get_detection_rate(test_key, corruption_model, model_name, n_samples, n_classes=10):\n",
    "    ## sample from test set to generate perturbations \n",
    "    all_xs_test, true_labels_test, epsilons_test, all_ys_test, K_test, test_key = init_data(test_key, _type='test', n_samples=n_samples)\n",
    "    ## sample from train set to estimate tresholds\n",
    "    all_xs_train, true_labels_train, epsilons_train, all_ys_train, K_train, test_key = init_data(test_key, _type='train', n_samples=n_samples)\n",
    "\n",
    "    ## generate p_bayes for test set\n",
    "    all_generated_p_bayes, well_classified = generate_p_bayes(corruption_model, n_samples, all_xs_test, epsilons_test, true_labels_test, all_ys_test, K_test)\n",
    "    generated_predictions = np.argmax(all_generated_p_bayes, axis=1)\n",
    "\n",
    "    ## generate p_bayes for train set\n",
    "    all_true_p_bayes, well_classified = generate_p_bayes(corruption_model, n_samples, all_xs_train, epsilons_train, true_labels_train, all_ys_train, K_train, corruption=False)\n",
    "    true_predictions = np.argmax(all_true_p_bayes, axis=1)\n",
    "\n",
    "    means, stds = get_statistics(all_true_p_bayes, true_predictions, n_samples, n_classes)\n",
    "\n",
    "    ## construct ROC curve\n",
    "    detection_list, false_positives_list = [], []\n",
    "    for alpha in np.linspace(-2., 2, 100):\n",
    "        detections, false_positives = evaluate_treshold(alpha,\n",
    "        all_generated_p_bayes, generated_predictions,\n",
    "        all_true_p_bayes, true_predictions,\n",
    "        well_classified, means,\n",
    "        stds, n_samples\n",
    "        )\n",
    "        detection_list.append(detections)\n",
    "        false_positives_list.append(false_positives)\n",
    "\n",
    "    false_positives_list = np.array(false_positives_list)\n",
    "    detection_list = np.array(detection_list)\n",
    "\n",
    "    display_roc_curve(false_positives_list, detection_list, model_name, save=True)\n",
    "    detection_rate_5pc = detection_list[np.where(false_positives_list < 0.05)[0]].max()\n",
    "    print(f'Detection rate for 5% false positives on train set: {100*detection_rate_5pc:.2f}% ({model_type} model)')\n",
    "    return test_key, detection_rate_5pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_model = FastGradientSign(eta=0.3)\n",
    "model_name = \"FGS\"\n",
    "\n",
    "test_key, detection_rate = get_detection_rate(test_key, corruption_model, model_name, n_samples=100, n_classes=config.n_classes)\n",
    "\n",
    "corruption_model = DeepFool(config)\n",
    "model_name = \"DeepFool\"\n",
    "\n",
    "test_key, detection_rate = get_detection_rate(test_key, corruption_model, model_name, n_samples=100, n_classes=config.n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
